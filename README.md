# this is our final project that we propose a new framework to evaluate recommendations systems
In today’s web environment, recommendation systems have become a key way to
improve customer engagement and increase company revenues. According to AQOA and
McKinsey & Co, 35% of Amazon’s sales and 95% of Netflix’s recommended titles come
from their recommendation systems. The rapid emergence of these recommender systems
has created the need to develop appropriate frameworks to evaluate their performance
and relevance. The static context surrounding the advent of these systems has favored
the widespread use of an offline framework that omits the actual properties of streaming
data on production platforms such as Amazon and Netflix. This leads to an artificial
and illogical evaluation that makes the evaluation results indeterminate. Thus, the most
relevant algorithms in this framework are not always the best algorithms to adopt in
real platforms. In this dissertation, we propose a framework for evaluating recommender
systems that retains the realistic aspect of streaming data. Our proposal is based on time
window sampling techniques to model the dynamic aspect of the data. Subsequently,
our framework follows a stream message distribution approach to simulate the online
recommendation scenario as closely as possible. Our experiments conducted on a real
dataset showed the difference between the evaluation results on a static offline framework
and following the guidelines of our dynamic proposal.
